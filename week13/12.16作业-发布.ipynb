{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.16 课后作业： 股票时间序列分析\n",
    "------\n",
    "\n",
    "本次作业将使用线性自回归模型和简单的神经网络模型对某公司每日收盘价格序列进行分析和预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:17:37.895231Z",
     "start_time": "2020-12-16T16:17:36.098180Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv, time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T15:37:19.774425Z",
     "start_time": "2020-12-16T15:37:19.673820Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'GOOGL_2006-01-01_to_2018-01-01.csv'\n",
    "# skip the header. extract the 4th column (\"close\")\n",
    "data = torch.from_numpy(np.loadtxt(filename, skiprows=1, delimiter=\",\", usecols=4)).float()\n",
    "Len = len(data)\n",
    "print(\"Totally\", Len, \"time steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在$K$阶的自回归模型中，我们对时间序列建模如下：对任意$t$，\n",
    "$$\n",
    "x_{t} = f_\\theta(x_{t-K}, x_{t-K+1}, ..., x_{t-1}) + \\epsilon_{t},\n",
    "$$\n",
    "其中$\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$.\n",
    "\n",
    "为了求出最优的模型参数$\\theta$，我们求解这样的优化问题：\n",
    "$$\n",
    "\\min_{\\theta} \\mathcal{L}_\\text{train}(\\theta) := \\sum_{t\\in \\mathcal{I}_{\\text{train}}} \\Vert f_\\theta(x_{t-K}, x_{t-K+1}, ..., x_{t-1}) - x_t \\Vert_2^2\n",
    "$$\n",
    "\n",
    "在线性自回归模型中，我们设$f_\\theta(x_1, ..., x_K) = w_0 + \\sum_{k=1}^K w_kx_k$是一个线性模型，其中参数$\\theta = \\{w_0, w_1, ..., w_K\\}$；而在神经网络模型中，$f_\\theta$可以拟合更加复杂的映射。\n",
    "\n",
    "-----\n",
    "下面首先定义一个`Pytorch`中的标准数据集类，这是个可以随机访问和迭代的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T15:08:33.407765Z",
     "start_time": "2020-12-16T15:08:33.368762Z"
    }
   },
   "outputs": [],
   "source": [
    "class StockDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, K):\n",
    "        self.data = data\n",
    "        self.K = K\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.K\n",
    "    \n",
    "    def __getitem__(self, idx): # return the `idx` - th object (x, y) in the dataset\n",
    "        return ( self.data[idx : idx + K], \n",
    "                self.data[idx + K].unsqueeze(0) )# insert a new axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 线性自回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:33:59.632137Z",
     "start_time": "2020-12-16T16:33:59.616537Z"
    }
   },
   "outputs": [],
   "source": [
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:34:00.153167Z",
     "start_time": "2020-12-16T16:34:00.142166Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = StockDataset(data[:-500], K)\n",
    "test_data = StockDataset(data[-500:], K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:34:00.665196Z",
     "start_time": "2020-12-16T16:34:00.638195Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data 可迭代\n",
    "for x, y in train_data:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集的$X \\in \\mathbb{R}^{N \\times (K+1)}$和$y \\in \\mathbb{R}^{N\\times 1}$。$X$的每一行表示一个$K+1$维数据点（新加的一维用来把常数项放进求和号中，简化表达），各个点的回归目标保存在$y$中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:34:02.347047Z",
     "start_time": "2020-12-16T16:34:02.052638Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.cat((torch.stack([x for x, _ in train_data]), torch.ones(len(train_data), 1)), axis = 1)\n",
    "y = torch.stack([y for _, y in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设线性模型参数$w\\in \\mathbb{R}^{K+1}$，则正规方程$\\min_w \\Vert Xw - y \\Vert_2^2$的解为$\\hat{w} = (X^TX)^{-1}X^Ty$. \n",
    "\n",
    "**请你在下面补充代码，求出最优的参数$\\hat{w}$。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:34:03.220079Z",
     "start_time": "2020-12-16T16:34:03.121474Z"
    }
   },
   "outputs": [],
   "source": [
    "W = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请你在下面补充代码，检查求出的模型在测试集`test_data`上的表现，求出测试集上的平均均方误差。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:34:05.258730Z",
     "start_time": "2020-12-16T16:34:05.191127Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = \n",
    "y_test = \n",
    "loss = \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算模型在整个序列上的估计值，并可视化。** 结合系数`w`，你发现了什么现象，如何解释模型的行为？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:34:11.918222Z",
     "start_time": "2020-12-16T16:34:11.309610Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = \n",
    "\n",
    "plt.plot(y_hat)\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:33:16.671216Z",
     "start_time": "2020-12-16T16:33:16.655616Z"
    }
   },
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**调整窗口宽度$K$的大小，对比Loss，你有什么发现？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 神经网络模型\n",
    "\n",
    "在这里，我们设计一个简单的两到三层的神经网络来预测时间序列。\n",
    "\n",
    "首先将训练集进一步抽出一部分作为验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:42:24.832682Z",
     "start_time": "2020-12-16T16:42:24.816082Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(train_data))\n",
    "valid_size = len(train_data) - train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造`Pyrorch`中标准的`DataLoader`类。你可以更改其中的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:43:12.190979Z",
     "start_time": "2020-12-16T16:43:12.167379Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter  = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 64)\n",
    "valid_iter = torch.utils.data.DataLoader(valid_data, batch_size = 64)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义模型及损失函数。** 提示：为了加速训练，你可以考虑在forward中，先对网络的输入（每个长度为K的片段）进行归一化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T17:11:45.669976Z",
     "start_time": "2020-12-16T17:11:45.630374Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "\n",
    "net = \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T17:06:40.269259Z",
     "start_time": "2020-12-16T17:06:40.238059Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型。`evaluate_model`用于评估模型`net`在`data_iter`上的表现，给出平均损失；`train`会在`train_iter`上训练模型`net`，优化器选择`optimizer`，并用`valid_iter`进行验证及early stop。\n",
    "\n",
    "**请你完善以下代码。**代码仅供参考，觉得不方便的地方，可以直接修改。\n",
    "\n",
    "提示：如果你是用cuda进行训练，请务必把网络和需要在GPU上进行运算的tensor移动到GPU上。参与运算的两个tensor必须同时在GPU显存或CPU内存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T17:04:32.811454Z",
     "start_time": "2020-12-16T17:04:32.750851Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import EarlyStop\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def evaluate_model(data_iter, net, loss, device = device):\n",
    "    loss_sum, n = 0.0, 0\n",
    "    net = net.to(device)\n",
    "    with torch.no_grad():\n",
    "        net.eval() \n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            \n",
    "        net.train()\n",
    "    return loss_sum / n\n",
    "\n",
    "def train(net, train_iter, valid_iter, loss, optimizer, max_epochs = 100, early_stop = None, device = device):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        train_loss, n, start = 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            \n",
    "\n",
    "            train_loss += l.cpu().item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "            \n",
    "        valid_loss = \n",
    "        \n",
    "        print('epoch %d, train loss %.8f , valid loss %.8f, time %.1f sec' % (epoch, train_loss, valid_loss, time.time() - start))\n",
    "        \n",
    "        if (early_stop):\n",
    "            if (early_stop(valid_loss, net, optimizer)):\n",
    "                break\n",
    "    \n",
    "    if (early_stop):\n",
    "        checkpoint = torch.load(early_stop.save_name)\n",
    "        net.load_state_dict(checkpoint[\"net\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T17:12:04.019436Z",
     "start_time": "2020-12-16T17:11:50.889339Z"
    }
   },
   "outputs": [],
   "source": [
    "train(net, train_iter, valid_iter, loss, \n",
    "      optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=  , weight_decay = 0.0001), \n",
    "      max_epochs = 300, early_stop = EarlyStop(patience = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T17:12:16.719187Z",
     "start_time": "2020-12-16T17:12:16.621582Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"test loss: \", evaluate_model(test_iter, net, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**哪个模型的表现更好？你有哪些思考？**\n",
    "\n",
    "另外，你也可以尝试别的模型，如上课提到的像WaveNet那样进一步堆叠网络。你可以另附代码或直接修改上面的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
