# textrank提取关键词作业的报告
## 1. 总括
这次作业中实现了textrank算法,并根据自己的思路进行优化,同时调用了pke库中的TF-IDF,textrank,topicrank,singlerank等算法,计算了Purity,Recall,F-score等参数,并进行了比较.

## 2. 关于数据的预处理
这部分主要调用了nltk库.首先将所有字母转换为小写,然后使用tokenize函数对摘要分词,再使用pos_tag函数为每个单词标注词性,并提取出名词,形容词作为可能的关键词(原论文中说,仅对名词,形容词建图能显著提高结果).最后使用lemmatize函数提取词干(将名词复数转化为单数,将比较级,最高级的形容词还原为原型).再利用整个文本对可能的关键词建图连边,迭代100次后,选出权重排名前WORDCOUNT(经过手动调参,取25)的单词,再找出文本中所有在这WORDCOUNT个单词中,两个词都有出现的二字词组,取出现次数>=WORDREP(经过手动调参,取8)的词组输出

## 3. 我对textrank的优化
原textrank算法中,单词之间的边权为它们在长度为$k$的窗口中共现次数.但显然,单词之间距离越近,他们的关联性越强,连边的边权应该越大.于是每次当两个单词$wd_i$,$wd_j$在长为$k$的窗口中共现时,就将他们之间的边权$+=\frac1{(i-j)^2}$(距离的平方反比),最后再对每个点的出边边权归一化.这样提高了F值.关于其他的连边方式(如边权为距离反比,立方反比,以及边权都相同),在后文中给出了对比

## 4. 对输出结果的评分
将.key文件中的词组都转换为小写,并提取词干,再与.mykey中的词组进行对比,计算每一组文件的P,R,F值,并取平均值,最后输出到result.txt中

## 5. 不同方法与参数的结果对比(所有文件平均值)
|算法|Purity|Recall|F-score|
|:-:|:-:|:-:|:-:|
|textrank 距离立方反比|0.193301|0.176643|0.165552|
|textrank 距离平方反比|0.193770|0.186584|0.169610|
|textrank 距离反比|0.207835|0.162047|0.164199|
|textrank 常数|
|textrank pke|
|topicrank pke|
|singlerank pke|
|TF-IDF pke|
